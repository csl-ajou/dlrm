###### rm1 cpu ###### 

# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_10000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=15000000-15000000-15000000-15000000-15000000-15000000-15000000-15000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_15000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=20000000-20000000-20000000-20000000-20000000-20000000-20000000-20000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_20000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=25000000-25000000-25000000-25000000-25000000-25000000-25000000-25000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_25000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=26000000-26000000-26000000-26000000-26000000-26000000-26000000-26000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_26000000.log


###### rm1 uvm ######
# USE_UVM=1 python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_uvm_10000000.log
# USE_UVM=1 python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=15000000-15000000-15000000-15000000-15000000-15000000-15000000-15000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_uvm_15000000.log
# USE_UVM=1 python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=20000000-20000000-20000000-20000000-20000000-20000000-20000000-20000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_uvm_20000000.log
# USE_UVM=1 python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=25000000-25000000-25000000-25000000-25000000-25000000-25000000-25000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_uvm_25000000.log
# USE_UVM=1 python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=26000000-26000000-26000000-26000000-26000000-26000000-26000000-26000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_uvm_26000000.log

###### rm1 gpu ######
#python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_gpu_10000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=15000000-15000000-15000000-15000000-15000000-15000000-15000000-15000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_cpu_15000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=20000000-20000000-20000000-20000000-20000000-20000000-20000000-20000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_cpu_20000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=25000000-25000000-25000000-25000000-25000000-25000000-25000000-25000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_cpu_25000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=26000000-26000000-26000000-26000000-26000000-26000000-26000000-26000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_cpu_26000000.log

###### rm1 emb cpu ######
# python dlrm_s_pytorch_emb.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_10000000.log
# python dlrm_s_pytorch_emb.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=15000000-15000000-15000000-15000000-15000000-15000000-15000000-15000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_15000000.log
# python dlrm_s_pytorch_emb.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=20000000-20000000-20000000-20000000-20000000-20000000-20000000-20000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_20000000.log
# python dlrm_s_pytorch_emb.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=25000000-25000000-25000000-25000000-25000000-25000000-25000000-25000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_25000000.log
# python dlrm_s_pytorch_emb.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=26000000-26000000-26000000-26000000-26000000-26000000-26000000-26000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_cpu_26000000.log


# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > 210408_rm1_cpu_bag_10000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=15000000-15000000-15000000-15000000-15000000-15000000-15000000-15000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > 210408_rm1_cpu_bag_15000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=20000000-20000000-20000000-20000000-20000000-20000000-20000000-20000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > 210408_rm1_cpu_bag_20000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=25000000-25000000-25000000-25000000-25000000-25000000-25000000-25000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > 210408_rm1_cpu_bag_25000000.log
# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=26000000-26000000-26000000-26000000-26000000-26000000-26000000-26000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > 210408_rm1_cpu_bag_26000000.log


# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > 210414_rm1_bag_10000000.log
# python dlrm_s_pytorch_emb.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > 210414_rm1_10000000.log

# python dlrm_s_pytorch.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > 210414_rm1_gpu_bag_10000000.log
# python dlrm_s_pytorch_emb.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=10 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > 210414_rm1_gpu_10000000.log


### hybrid => hybrid1 ###
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_hy_10000000.log
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=15000000-15000000-15000000-15000000-15000000-15000000-15000000-15000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_hy_15000000.log
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=20000000-20000000-20000000-20000000-20000000-20000000-20000000-20000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_hy_20000000.log
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=25000000-25000000-25000000-25000000-25000000-25000000-25000000-25000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_hy_25000000.log
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=26000000-26000000-26000000-26000000-26000000-26000000-26000000-26000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_hy_26000000.log

### hybrid lu => different lookup number ###
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_lu_hy10000000.log
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=15000000-15000000-15000000-15000000-15000000-15000000-15000000-15000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=120 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_lu_hy15000000.log
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=20000000-20000000-20000000-20000000-20000000-20000000-20000000-20000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=160 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_lu_hy20000000.log
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=25000000-25000000-25000000-25000000-25000000-25000000-25000000-25000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=200 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_lu_hy25000000.log
# python dlrm_s_pytorch_hybrid.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=26000000-26000000-26000000-26000000-26000000-26000000-26000000-26000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=260 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time > rm1_lu_hy26000000.log

### hybrid2 => cuda host ###
# python dlrm_s_pytorch_hybrid2.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=10000000-10000000-10000000-10000000-10000000-10000000-10000000-10000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_hy2_10000000.log
# python dlrm_s_pytorch_hybrid2.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=15000000-15000000-15000000-15000000-15000000-15000000-15000000-15000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_hy2_15000000.log
# python dlrm_s_pytorch_hybrid2.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=20000000-20000000-20000000-20000000-20000000-20000000-20000000-20000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_hy2_20000000.log
# python dlrm_s_pytorch_hybrid2.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=25000000-25000000-25000000-25000000-25000000-25000000-25000000-25000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_hy2_25000000.log
# python dlrm_s_pytorch_hybrid2.py --arch-mlp-bot=128-64-32 --arch-mlp-top=256-64-1 --arch-embedding-size=30000000-30000000-30000000-30000000-30000000-30000000-30000000-30000000 --arch-sparse-feature-size=32 --num-indices-per-lookup-fixed=true --num-indices-per-lookup=80 --num-batches=30 --mini-batch-size 1024 --arch-interaction-op='cat' --print-time --use-gpu > rm1_hy2_30000000.log
